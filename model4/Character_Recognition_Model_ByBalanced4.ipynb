{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mbCmQVhMXgVa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import EMNIST\n",
        "# import torch.optim as optim\n",
        "# from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "# from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i2dxVTwSXumG"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=1.0),  # Flip the image horizontally with 100% probability\n",
        "    transforms.RandomRotation((90, 90)),  # Rotate 90 degrees anti-clockwise\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xsbwdnNzXuqc"
      },
      "outputs": [],
      "source": [
        "# classes = EMNIST(root='data/', split='balanced', train=True, download=True, transform=transform).classes\n",
        "\n",
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'd', 'e', 'f', 'g', 'h', 'n', 'q', 'r', 't']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CrJu0jHcXu9b"
      },
      "outputs": [],
      "source": [
        "# Define a simple CNN architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 47)  # 47 classes in the 'byclass' split\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPKSEzelXvGZ",
        "outputId": "66447d34-025f-4276-cf12-2c7c80d44799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SimpleCNN()\n",
        "\n",
        "# Train the model\n",
        "# train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=5)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Run code from here to use pretrained weights\n",
        "model.load_state_dict(torch.load(\"./model4_weights.pth\", weights_only=True, map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qKR386tAYLKv"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess the image\n",
        "def preprocess_image(img, invert=False, resize=True, show_output=True):\n",
        "    if invert:\n",
        "        # Invert the colors\n",
        "        img = np.bitwise_not(img)\n",
        "\n",
        "        if show_output:\n",
        "            # Display the original grayscale image\n",
        "            plt.figure()\n",
        "            plt.title(\"Inverted Grayscale Image\")\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    if resize:\n",
        "        # Resize the image to 28x28\n",
        "        img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        if show_output:\n",
        "            # Display the resized image\n",
        "            plt.figure()\n",
        "            plt.title(\"Resized Image (28x28)\")\n",
        "            plt.imshow(img, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "    # Define the transformations: convert to tensor and normalize\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    # Apply the transformations\n",
        "    img_tensor = transform(img)\n",
        "\n",
        "    # Add batch dimension (1, 1, 28, 28)\n",
        "    img_tensor = img_tensor.unsqueeze(0)\n",
        "\n",
        "    return img, img_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Y7ciK_duz7",
        "outputId": "9814b78e-33c4-4288-9756-8358eade7465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=47, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()  # Set the model to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ieb55a9BYXqf"
      },
      "outputs": [],
      "source": [
        "# Function to predict the label of the processed image\n",
        "def predict_image(model, image_tensor):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor.to(device))\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        return predicted.item(), probabilities.squeeze().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4Qq-0IsRdu0F"
      },
      "outputs": [],
      "source": [
        "def get_top_n_classes(model, img_tensor, n=5, prob_threshold=0.00):\n",
        "    \"\"\"\n",
        "    Returns the top n classes and their probabilities for a given image tensor using the provided model\n",
        "    Filters the model output based on the probability threshold, returns n best options (if they exist)\n",
        "        Parameters:\n",
        "            - model: The model used for prediction.\n",
        "            - img_tensor: The image tensor to be predicted.\n",
        "            - n (optional): The number of top classes to return. Default is 5.\n",
        "            - prob_threshold (optional): The probability threshold for considering a class. Default is 0.001.\n",
        "        Returns:\n",
        "            - sorted_classes: A list of the top n classes.\n",
        "            - sorted_probs: A list of the corresponding probabilities for the top n classes.\n",
        "    \"\"\"\n",
        "\n",
        "    global classes\n",
        "    _, probs = predict_image(model, img_tensor)\n",
        "\n",
        "    # Define the mapping from lowercase to uppercase\n",
        "    lower_to_upper = {\n",
        "        'a': 'A', 'b': 'B', 'd': 'D', 'e': 'E', 'f': 'F',\n",
        "        'g': 'G', 'h': 'H', 'n': 'N', 'q': 'Q', 'r': 'R', 't': 'T'\n",
        "    }\n",
        "\n",
        "    # Initialize the new_classes and new_probs dictionaries\n",
        "    new_classes = list('0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "    new_probs = {cls: 0.0 for cls in new_classes}\n",
        "\n",
        "    # Merge the probabilities for lowercase and uppercase letters\n",
        "    for cls, prob in zip(classes, probs):\n",
        "        if cls in lower_to_upper:\n",
        "            new_probs[lower_to_upper[cls]] += prob\n",
        "        else:\n",
        "            new_probs[cls] += prob\n",
        "\n",
        "    # Sort the merged probabilities\n",
        "    sorted_vals = sorted(new_probs.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Filter based on probability threshold and get the top n classes\n",
        "    filtered_vals = [val for val in sorted_vals if val[1] >= prob_threshold][:n]\n",
        "\n",
        "    if not filtered_vals:\n",
        "        return None\n",
        "\n",
        "    sorted_classes = [val[0] for val in filtered_vals]\n",
        "    sorted_probs = [val[1] for val in filtered_vals]\n",
        "\n",
        "    return sorted_classes, sorted_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4XxzT0odu0I"
      },
      "source": [
        "## Helper classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fdDFxdpJdu0N"
      },
      "outputs": [],
      "source": [
        "class output_char():\n",
        "    \"\"\"\n",
        "        Represents an output character with its associated information.\n",
        "\n",
        "    Attributes:\n",
        "        - character: The image of the character stored as a numpy array.\n",
        "        - predicted_chars: The top predicted characters.\n",
        "        - predicted_probs: The respective probabilities of the predicted characters.\n",
        "        - corr: The coordinates of the character in the original image.\n",
        "        - shape: The shape of the character image.\n",
        "    \"\"\"\n",
        "    def __init__(self, char_img, probs, classes, col_corr, row_corr, width, height):\n",
        "        self.character = char_img\n",
        "        self.predicted_chars = classes\n",
        "        self.predicted_probs = probs\n",
        "        self.corr = (row_corr, col_corr)\n",
        "        self.shape = (height, width)\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        return \\\n",
        "            f\"Character's coordinates in original image: {self.corr}\\n\" \\\n",
        "            f\"Top predicted characters : {self.predicted_chars}\\n\" \\\n",
        "            f\"Respective probabilities : {self.predicted_probs}\\n\" \\\n",
        "            f\"Shape of image : {self.shape}\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ml3_vhcbdu0O"
      },
      "outputs": [],
      "source": [
        "def get_output_char(model, img_tensor, img_numpy, col, row, width, height):\n",
        "    \"\"\"\n",
        "        Returns the an object of output_char class containing the predicted character,\n",
        "        it's corrdinates, shape and the top predicted characters and their probabilities.\n",
        "    Parameters:\n",
        "        model (object): The model used for prediction.\n",
        "        img_tensor (object): The image tensor.\n",
        "        img_numpy (object): The image numpy array.\n",
        "        col (int): The col corrdinate of the character in the original image.\n",
        "        row (int): The row corrdinate of the character in the original image.\n",
        "        width (int): The width of cropped character ( img_numpy ).\n",
        "        height (int): The height of cropped character ( img_numpy ).\n",
        "    Returns:\n",
        "        None or object of output_char\n",
        "    \"\"\"\n",
        "\n",
        "    prediction = get_top_n_classes(model, img_tensor)\n",
        "    if prediction is None:\n",
        "        return None\n",
        "\n",
        "    classes, probs = prediction\n",
        "\n",
        "    return output_char(img_numpy, probs, classes, col_corr=col, row_corr=row, width=width, height=height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z6VziLBddu0P"
      },
      "outputs": [],
      "source": [
        "class line_chars():\n",
        "    \"\"\"\n",
        "        A class representing a line of characters ( objects of output_char class ).\n",
        "    Attributes:\n",
        "        - starty:   The starting y-coordinate of the line.\n",
        "        - endy:     The ending y-coordinate of the line.\n",
        "        - chars:    A list of characters (objects of output_char) in the line.\n",
        "    Methods:\n",
        "        - __init__(self, y1, y2, char): Initializes a line_chars object with the given y-coordinates and character (object of output_char).\n",
        "        - can_be_added(self, y1, y2): Checks if a character with given y-coordinates can be added to the line or should be added to some other line instead.\n",
        "        - add_char(self, y1, y2, char): Adds a character to can_be_added() is True.\n",
        "        - sort_characters(self): Sorts the characters in the line based on their starting x-corrdinates value.\n",
        "    \"\"\"\n",
        "    def __init__(self, y1, y2, char):\n",
        "        self.starty = y1\n",
        "        self.endy = y2\n",
        "        self.chars = [char]\n",
        "\n",
        "\n",
        "    def can_be_added(self, y1, y2):\n",
        "        return (y1 >= self.starty and y1 <= self.endy) or (y2 >= self.starty and y2 <= self.endy)\n",
        "\n",
        "\n",
        "    def add_char(self, y1, y2, char):\n",
        "        if not self.can_be_added(y1, y2):\n",
        "            return\n",
        "\n",
        "        self.chars.append(char)\n",
        "        # TODO: Don't update the lines' y-coordinates and just rely on the initial values\n",
        "        #       provided by the line segmentation code\n",
        "        self.starty = min(self.starty, y1)\n",
        "        self.endy = max(self.endy, y2)\n",
        "\n",
        "\n",
        "    def sort_characters(self):\n",
        "        self.chars = sorted(self.chars, key=lambda x: x.corr[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zeq6Z8qQdu0Q"
      },
      "outputs": [],
      "source": [
        "def append_to_correct_line(lines_list, row, h, char):\n",
        "    \"\"\"\n",
        "        Appends a character to the correct line in a list of line_chars objects.\n",
        "    Parameters:\n",
        "        - lines_list (list): A list of line_chars objects.\n",
        "        - row (int): The starting y-offset of the character on the image (row number).\n",
        "        - h (int): The height of the character.\n",
        "        - char (object of output_char): The character to be added.\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    lines_count = len(lines_list)\n",
        "    line_added = False\n",
        "\n",
        "    for line_num in range(lines_count):\n",
        "        if lines_list[line_num].can_be_added(row, row + h):\n",
        "            lines_list[line_num].add_char(row, row + h, char)\n",
        "            line_added = True\n",
        "            break\n",
        "    if not line_added:\n",
        "        lines_list.append(line_chars(row, row + h, char))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ItiLqZTudu0T"
      },
      "outputs": [],
      "source": [
        "class word():\n",
        "    def __init__(self, char):\n",
        "        \"\"\"\n",
        "            Initializes a word object with an object of output_char class.\n",
        "        Parameters:\n",
        "            - char: An output_char object representing the first character of the word.\n",
        "        \"\"\"\n",
        "        self.startx = char.corr[1]\n",
        "        self.endx = char.corr[1], char.shape[1]\n",
        "        self.characters = [char]\n",
        "\n",
        "\n",
        "    def can_add_char(self, char, word_spacing_thresh):\n",
        "        \"\"\"\n",
        "            Checks if a character can be added to the word based on the corrdinates of the given character\n",
        "            & the last character of the current word.\n",
        "        Parameters:\n",
        "            - char: The output_char object to be added.\n",
        "            - word_spacing_thresh: The maximum allowed spacing between characters.\n",
        "        Returns:\n",
        "            - True if the character can be added, False otherwise.\n",
        "        \"\"\"\n",
        "        last_char_end = self.characters[-1].corr[1] + self.characters[-1].shape[1]\n",
        "\n",
        "        # We can add the provided character if it starts after the current character and is within the word_spacing_thresh\n",
        "        return char.corr[1] <= last_char_end + word_spacing_thresh #and char.corr[1] >= last_char_end\n",
        "\n",
        "\n",
        "    def add_char(self, char, word_spacing_thresh, verify=True):\n",
        "        \"\"\"\n",
        "            Adds a character to the word if can_add_char is True or verification is forced to be off.\n",
        "        Parameters:\n",
        "            - char: The output_char object to be added.\n",
        "            - word_spacing_thresh: The maximum allowed spacing between characters to consider it the same word.\n",
        "            - verify: A boolean indicating whether to verify if the character can be added or forcefully add it.\n",
        "        \"\"\"\n",
        "        if verify and not self.can_add_char(char, word_spacing_thresh):\n",
        "            return\n",
        "\n",
        "        self.characters.append(char)\n",
        "        self.endx = char.corr[1] + char.shape[1]\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            - A string representing the word.\n",
        "        \"\"\"\n",
        "        return ''.join([x.predicted_chars[0] for x in self.characters])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "k0giXiYndu0V"
      },
      "outputs": [],
      "source": [
        "def process_image(img_path, ksize=3, t1=21, t2=5):\n",
        "    \"\"\"\n",
        "        Process the provided image using opencv2 to\n",
        "        remove shadows & put more emphasis on the text.\n",
        "    Params:\n",
        "        img_path:       str         : Path of the image to process on disk\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    image = cv2.imread(img_path)\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (ksize, ksize), 0)\n",
        "\n",
        "    # Apply adaptive thresholding\n",
        "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                    cv2.THRESH_BINARY, t1, t2)\n",
        "\n",
        "    # Apply morphological operations\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    return morph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFOHXz0Mdu0W"
      },
      "source": [
        "## Helper functions for extracting words out of lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q7_dlltOdu0W"
      },
      "outputs": [],
      "source": [
        "def get_sorted_contours(img, area_threshold=50):\n",
        "    \"\"\"\n",
        "        Extract the contours from the provided image and sort them based on their (x,y).\n",
        "    Args:\n",
        "        img (numpy.array): Output of cv2.imread() function. The image to get the contours from.\n",
        "        area_threshold (int, optional): Minimum area that a contour should have to be considered valid. Defaults to 50.\n",
        "    \"\"\"\n",
        "    def get_contour_1D_pos(bbox, img_width):\n",
        "        \"\"\"\n",
        "        Convert the provided coordinates to a 1D position similar to converting the indexes of a 2D matrix into 1D.\n",
        "        \"\"\"\n",
        "        x, y, _, _ = bbox\n",
        "        return y * img_width + x\n",
        "\n",
        "    _, img_w = img.shape\n",
        "    contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    filtered_contours = [contour for contour in contours if cv2.contourArea(contour) >= area_threshold]\n",
        "    sorted_contours = sorted(filtered_contours, key=lambda x: get_contour_1D_pos(cv2.boundingRect(x), img_w))\n",
        "\n",
        "    return sorted_contours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XN_cktfRdu0X"
      },
      "outputs": [],
      "source": [
        "def get_curr_contour(img, contour, padding=2):\n",
        "    \"\"\"\n",
        "        Extracts the current contour from an image and returns it as a square image.\n",
        "    Parameters:\n",
        "        - img: The input image.\n",
        "        - contour: The contour to extract.\n",
        "        - padding: The padding to add around the contour (default: 2 pixels).\n",
        "    Returns:\n",
        "        - curr_contour: The extracted contour as a square image ( numpy array ).\n",
        "    \"\"\"\n",
        "    # Implementation details...\n",
        "    pass\n",
        "\n",
        "    col, row, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "    dim = max(w, h) + padding\n",
        "    # Extra rows/cols to add to each side to make the image square\n",
        "    extra_row = (dim - h) // 2\n",
        "    extra_col = (dim - w) // 2\n",
        "\n",
        "    # starting dimensions of the square box\n",
        "    box_row_st, box_col_st = max(row - extra_row, 0), max(col - extra_col, 0)\n",
        "    curr_contour = img[box_row_st:box_row_st+ dim, box_col_st:box_col_st + dim].copy()\n",
        "    contour_h, contour_w = curr_contour.shape\n",
        "\n",
        "    # Fill the contour with 0s outside the actual location of the contour\n",
        "    for idx in range(contour_h):\n",
        "        for j in range(contour_w):\n",
        "            if cv2.pointPolygonTest(contour, (box_col_st + j, box_row_st + idx), False) < 0:\n",
        "                curr_contour[idx][j] = 0\n",
        "\n",
        "    return curr_contour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EvL4Aouudu0Y"
      },
      "outputs": [],
      "source": [
        "def get_characters_in_lines(img):\n",
        "    \"\"\"\n",
        "        Extracts the characters from an image, predict what characters they are using model\n",
        "        and group the results into lines ( objects of line_chars ).\n",
        "    Args:\n",
        "        img (numpy.ndarray): The input image.\n",
        "    Returns:\n",
        "        list: A list of objects of line_chars\n",
        "    \"\"\"\n",
        "\n",
        "    lines_list = []\n",
        "\n",
        "    temp_img = np.zeros(img.shape)\n",
        "\n",
        "    sorted_contours = get_sorted_contours(img)\n",
        "\n",
        "    for i in range(len(sorted_contours)):\n",
        "        col, row, w, h = cv2.boundingRect(sorted_contours[i])\n",
        "        curr_contour = get_curr_contour(img, sorted_contours[i])\n",
        "\n",
        "        # Process curr_contour with model and overlay at row, col\n",
        "        _, img_tensor = preprocess_image(curr_contour, show_output=False)\n",
        "\n",
        "        prediction = get_output_char(model, img_tensor, curr_contour, col, row, w, h)\n",
        "        if prediction is None:\n",
        "            continue\n",
        "\n",
        "        append_to_correct_line(lines_list, row, h, prediction)\n",
        "\n",
        "        cv2.putText(temp_img, prediction.predicted_chars[0], (col, row), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    plt.imshow(temp_img, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    return lines_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "A4i6ajBQdu0Z"
      },
      "outputs": [],
      "source": [
        "def get_words_list(lines_of_chars):\n",
        "    \"\"\"\n",
        "        Group characters in objects of line_chars into a list of objects of word class.\n",
        "    Args:\n",
        "        lines_of_chars (list): A list of line_chars objects.\n",
        "    Returns:\n",
        "        list: A 2D list of words, where word[i] = List of object of word representing words in line i.\n",
        "    \"\"\"\n",
        "    word_list = []\n",
        "    for line_num, line_of_characters in enumerate(lines_of_chars):\n",
        "        line_of_characters.sort_characters()\n",
        "\n",
        "        mean_char_width = np.mean([char.shape[1] for char in line_of_characters.chars])\n",
        "        word_spacing_thresh = mean_char_width\n",
        "\n",
        "        # New line\n",
        "        word_list.append([])\n",
        "        words_in_current_line = 0\n",
        "\n",
        "        for character in line_of_characters.chars:\n",
        "            if words_in_current_line > 0 and word_list[line_num][-1].can_add_char(character, word_spacing_thresh):\n",
        "                word_list[line_num][-1].add_char(character, word_spacing_thresh, verify=False)\n",
        "            else:\n",
        "                word_list[line_num].append(word(character))\n",
        "                words_in_current_line += 1\n",
        "\n",
        "    return word_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T-vzc75edu0Z"
      },
      "outputs": [],
      "source": [
        "def get_words_list_from_image(img_name, show_image=False):\n",
        "    \"\"\"\n",
        "        Extracts a 2D list of words, where word[i] = List of object of word representing words in line i.\n",
        "    Parameters:\n",
        "        - img_name (str): The name of the image file.\n",
        "        - show_image (bool): Whether to display the processed / binarized image.\n",
        "    Returns:\n",
        "    - words_list (list of list of objects of word): A list of words extracted from the image.\n",
        "    \"\"\"\n",
        "    processed_img = process_image(img_name)\n",
        "    inverted = np.bitwise_not(processed_img)\n",
        "\n",
        "    if show_image:\n",
        "        plt.figure()\n",
        "        plt.title(\"Processed Image\")\n",
        "        plt.imshow(inverted, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    lines = get_characters_in_lines(inverted)\n",
        "\n",
        "    return get_words_list(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "328Nbss7du0b"
      },
      "outputs": [],
      "source": [
        "def print_words_list(words_list):\n",
        "    \"\"\"\n",
        "        Provided a 2D list of word objects, prints the words Line by Line.\n",
        "\n",
        "    Args:\n",
        "        words_list (List of List[word]): The return value of get_words_list_from_image or get_words_list.\n",
        "    \"\"\"\n",
        "    for line in words_list:\n",
        "        for word in line:\n",
        "            print(word, end=' ')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "uVvWtvrrdu0c",
        "outputId": "180ca39b-c44e-42e2-fc48-da7d47d5dab4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L \n",
            "TLI7DLG HQ 0I S YDUX SAMPIC WF \n",
            "MY NCQME DLS NQFHCIW \n",
            "LLDW AYA YDU \n",
            "TTL QM WOQICLMG WDBN CYWFURECN7LDTLJ \n"
          ]
        }
      ],
      "source": [
        "img_name = './sample2.jpeg'\n",
        "\n",
        "words_list = get_words_list_from_image(img_name)\n",
        "print_words_list(words_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt_5CC81m-B8"
      },
      "source": [
        "using vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample word\n",
        "sample_word = words_list[1][5]  # word location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QuqV0i689Xs",
        "outputId": "0efd6969-2ca5-47f1-b7b5-03b58472a8cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /home/yilliee/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "# Download the nltk words corpus\n",
        "nltk.download('words')\n",
        "vocabulary = set(words.words())\n",
        "\n",
        "# Function to extract top predictions and probabilities\n",
        "def get_top_predictions_matrix(word, n=5):\n",
        "    top_predictions = [char.predicted_chars[:n] for char in word.characters]\n",
        "    top_probabilities = [char.predicted_probs[:n] for char in word.characters]\n",
        "\n",
        "    max_length = max(len(preds) for preds in top_predictions)\n",
        "\n",
        "    for preds in top_predictions:\n",
        "        while len(preds) < max_length:\n",
        "            preds.append('')\n",
        "\n",
        "    for probs in top_probabilities:\n",
        "        while len(probs) < max_length:\n",
        "            probs.append(0.0)\n",
        "\n",
        "    top_predictions_matrix = np.array(top_predictions)\n",
        "    top_probabilities_matrix = np.array(top_probabilities)\n",
        "\n",
        "    return top_predictions_matrix, top_probabilities_matrix\n",
        "\n",
        "# Function to correct a word using the nltk vocabulary\n",
        "def correct_word_using_vocabulary(top_predictions_matrix, top_probabilities_matrix, vocabulary):\n",
        "    best_word = None\n",
        "    best_prob = 0\n",
        "\n",
        "    candidates = product(*top_predictions_matrix)\n",
        "\n",
        "    for candidate in candidates:\n",
        "        candidate_word = ''.join(candidate).lower()\n",
        "        if candidate_word in vocabulary:\n",
        "            combined_prob = np.prod([top_probabilities_matrix[i][top_predictions_matrix[i].tolist().index(candidate[i])] for i in range(len(candidate))])\n",
        "            if combined_prob > best_prob:\n",
        "                best_word = candidate_word\n",
        "                best_prob = combined_prob\n",
        "\n",
        "    return best_word, best_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Predictions Matrix:\n",
            "[['S' 'G' '5' 'F' '8']\n",
            " ['A' 'Q' 'R' 'G' 'I']\n",
            " ['M' 'W' 'N' 'H' 'A']\n",
            " ['P' 'F' '9' 'Q' 'A']\n",
            " ['I' 'F' 'L' 'T' 'J']\n",
            " ['C' 'E' 'G' 'Q' '0']]\n",
            "\n",
            "Top Probabilities Matrix:\n",
            "[[9.9999714e-01 2.5721386e-06 2.0653370e-07 2.4966923e-08 2.2372065e-08]\n",
            " [6.2109512e-01 3.7682000e-01 2.0496077e-03 3.2703250e-05 2.2703416e-06]\n",
            " [1.0000000e+00 2.0925022e-09 4.6274874e-14 9.3335805e-17 5.6804606e-18]\n",
            " [1.0000000e+00 3.0572394e-08 2.4496222e-10 2.2899974e-11 1.4466954e-11]\n",
            " [4.7541726e-01 3.1216079e-01 8.1921443e-02 7.9033360e-02 4.3462709e-02]\n",
            " [9.9925452e-01 7.3024392e-04 6.1745486e-06 5.5973442e-06 3.2385012e-06]]\n",
            "\n",
            "Predicted Word: SAMPIC\n",
            "Corrected Word: sample\n",
            "Combined Probability: 3.7155437894398347e-05\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the top predictions and their probabilities\n",
        "top_predictions_matrix, top_probabilities_matrix = get_top_predictions_matrix(sample_word, n=5)\n",
        "\n",
        "# Correct the word using the vocabulary\n",
        "corrected_word, combined_prob = correct_word_using_vocabulary(top_predictions_matrix, top_probabilities_matrix, vocabulary)\n",
        "\n",
        "# Display the corrected word and its combined probability\n",
        "print(\"Top Predictions Matrix:\")\n",
        "print(top_predictions_matrix)\n",
        "print(\"\\nTop Probabilities Matrix:\")\n",
        "print(top_probabilities_matrix)\n",
        "print(f\"\\nPredicted Word: {sample_word}\")\n",
        "print(f\"Corrected Word: {corrected_word}\")\n",
        "print(f\"Combined Probability: {combined_prob}\")\n",
        "print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCsoX3_tFWsy"
      },
      "source": [
        "all possible words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40sIx0U5-yJn",
        "outputId": "ae34494b-bf56-4e28-f124-caf8b62a4e5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /home/yilliee/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import words\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "\n",
        "# Download the nltk words corpus\n",
        "nltk.download('words')\n",
        "vocabulary = set(words.words())\n",
        "\n",
        "# Function to extract top predictions and probabilities\n",
        "def get_top_predictions_matrix(word, n=5):\n",
        "    top_predictions = [char.predicted_chars[:n] for char in word.characters]\n",
        "    top_probabilities = [char.predicted_probs[:n] for char in word.characters]\n",
        "\n",
        "    max_length = max(len(preds) for preds in top_predictions)\n",
        "\n",
        "    for preds in top_predictions:\n",
        "        while len(preds) < max_length:\n",
        "            preds.append('')\n",
        "\n",
        "    for probs in top_probabilities:\n",
        "        while len(probs) < max_length:\n",
        "            probs.append(0.0)\n",
        "\n",
        "    top_predictions_matrix = np.array(top_predictions)\n",
        "    top_probabilities_matrix = np.array(top_probabilities)\n",
        "\n",
        "    return top_predictions_matrix, top_probabilities_matrix\n",
        "\n",
        "# Function to correct a word using the nltk vocabulary\n",
        "def correct_word_using_vocabulary(top_predictions_matrix, top_probabilities_matrix, vocabulary):\n",
        "    best_word = None\n",
        "    best_prob = 0\n",
        "    valid_words = []\n",
        "\n",
        "    candidates = product(*top_predictions_matrix)\n",
        "\n",
        "    for candidate in candidates:\n",
        "        candidate_word = ''.join(candidate).lower()\n",
        "        if candidate_word in vocabulary:\n",
        "            valid_words.append(candidate_word)\n",
        "            combined_prob = np.prod([top_probabilities_matrix[i][top_predictions_matrix[i].tolist().index(candidate[i])] for i in range(len(candidate))])\n",
        "            if combined_prob > best_prob:\n",
        "                best_word = candidate_word\n",
        "                best_prob = combined_prob\n",
        "\n",
        "    return best_word, best_prob, valid_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Predictions Matrix:\n",
            "[['S' 'G' '5' 'F' '8']\n",
            " ['A' 'Q' 'R' 'G' 'I']\n",
            " ['M' 'W' 'N' 'H' 'A']\n",
            " ['P' 'F' '9' 'Q' 'A']\n",
            " ['I' 'F' 'L' 'T' 'J']\n",
            " ['C' 'E' 'G' 'Q' '0']]\n",
            "\n",
            "Top Probabilities Matrix:\n",
            "[[9.9999714e-01 2.5721386e-06 2.0653370e-07 2.4966923e-08 2.2372065e-08]\n",
            " [6.2109512e-01 3.7682000e-01 2.0496077e-03 3.2703250e-05 2.2703416e-06]\n",
            " [1.0000000e+00 2.0925022e-09 4.6274874e-14 9.3335805e-17 5.6804606e-18]\n",
            " [1.0000000e+00 3.0572394e-08 2.4496222e-10 2.2899974e-11 1.4466954e-11]\n",
            " [4.7541726e-01 3.1216079e-01 8.1921443e-02 7.9033360e-02 4.3462709e-02]\n",
            " [9.9925452e-01 7.3024392e-04 6.1745486e-06 5.5973442e-06 3.2385012e-06]]\n",
            "\n",
            "Corrected Word: sample\n",
            "Combined Probability: 3.7155437894398347e-05\n",
            "\n",
            "Valid Words in Vocabulary:\n",
            "['sample', 'simple', 'finale']\n"
          ]
        }
      ],
      "source": [
        "# Get the top predictions and their probabilities\n",
        "top_predictions_matrix, top_probabilities_matrix = get_top_predictions_matrix(sample_word, n=5)\n",
        "\n",
        "# Correct the word using the vocabulary and get valid words\n",
        "corrected_word, combined_prob, valid_words = correct_word_using_vocabulary(top_predictions_matrix, top_probabilities_matrix, vocabulary)\n",
        "\n",
        "# Display the results\n",
        "print(\"Top Predictions Matrix:\")\n",
        "print(top_predictions_matrix)\n",
        "print(\"\\nTop Probabilities Matrix:\")\n",
        "print(top_probabilities_matrix)\n",
        "print(f\"\\nCorrected Word: {corrected_word}\")\n",
        "print(f\"Combined Probability: {combined_prob}\")\n",
        "print(\"\\nValid Words in Vocabulary:\")\n",
        "print(valid_words)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
